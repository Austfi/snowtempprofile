{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected station: Basin\n",
      "URL being fetched:\n",
      " https://stations.avalanche.state.co.us/tabular.php?title=A-Basin+SA-Pali+(A-BasinSA)+11920+ft&st=CAABP&date=2025-03-29+24&unit=e&area=caic&range=1200\n",
      "Plot URL being fetched:\n",
      " https://stations.avalanche.state.co.us/hplot.php?title=A-Basin+SA-Pali+(A-BasinSA)+11920+ft&st=CAABP&date=2025-03-29+24&unit=e&area=caic&range=1200\n",
      "Scraped 1144 data rows for station Basin.\n",
      "Wrote 1144 lines to basin_collect.txt.\n",
      "\n",
      "Selected station: Beck\n",
      "URL being fetched:\n",
      " https://stations.avalanche.state.co.us/tabular.php?title=Senator+Beck+%28CSAS%29+12186+ft&st=CASBK&date=2025-03-29+24&unit=e&area=caic&range=1200\n",
      "Plot URL being fetched:\n",
      " https://stations.avalanche.state.co.us/hplot.php?title=Senator+Beck+%28CSAS%29+12186+ft&st=CASBK&date=2025-03-29+24&unit=e&area=caic&range=1200\n",
      "Scraped 1056 data rows for station Beck.\n",
      "Wrote 1056 lines to beck_collect.txt.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "\n",
    "# Define a dictionary that stores multiple station options.\n",
    "# For each station, we include:\n",
    "#   - station_title and station_code for URL construction.\n",
    "#   - expected_numeric_cols: the number of numeric tokens returned by the station.\n",
    "#     (For Senator Beck (CSAS) this is 14 because it includes an extra SnoHt column,\n",
    "#      which we remove so the final output always has 13 numeric values.)\n",
    "station_options = {\n",
    "    \"Basin\": {\n",
    "        \"station_title\": \"A-Basin+SA-Pali+(A-BasinSA)+11920+ft\",\n",
    "        \"station_code\": \"CAABP\",\n",
    "        \"expected_numeric_cols\": 13\n",
    "    },\n",
    "    \"Beck\": {\n",
    "        \"station_title\": \"Senator+Beck+%28CSAS%29+12186+ft\",\n",
    "        \"station_code\": \"CASBK\",\n",
    "        \"expected_numeric_cols\": 14  # Raw data includes SnoHt that must be dropped.\n",
    "    }\n",
    "}\n",
    "\n",
    "def scrape_station_data(end_date_str=\"2025-03-01+24\", hours_range=72,\n",
    "                        station_title=\"A-Basin+SA-Pali+(A-BasinSA)+11920+ft\",\n",
    "                        station_code=\"CAABP\",\n",
    "                        expected_numeric_cols=13):\n",
    "    \"\"\"\n",
    "    Scrape the station data for the specified time range and station.\n",
    "    The final output lines will be in the form:\n",
    "      YYYY Mon DD HH:MM  Temp MxTp MnTp Dew(F) RH Spd Dir Gst SWIN SWOUT LWIN LWOUT NET\n",
    "    (0-based columns: 0=Year, 1=Month, 2=Day, 3=HH:MM, then 4-16 the numeric data.)\n",
    "    \n",
    "    For stations like Senator Beck (CSAS) that return an extra column (SnoHt),\n",
    "    the code removes that column so that the output always contains 13 numeric fields.\n",
    "    \"\"\"\n",
    "    url = (\n",
    "        \"https://stations.avalanche.state.co.us/tabular.php\"\n",
    "        f\"?title={station_title}\"\n",
    "        f\"&st={station_code}\"\n",
    "        f\"&date={end_date_str}\"\n",
    "        \"&unit=e\"\n",
    "        \"&area=caic\"\n",
    "        f\"&range={hours_range}\"\n",
    "    )\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError(f\"Request failed with status {response.status_code}\")\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    pre_tag = soup.find(\"pre\")\n",
    "    if not pre_tag:\n",
    "        raise ValueError(\"Could not find <pre> block with data.\")\n",
    "\n",
    "    lines = pre_tag.text.strip().split(\"\\n\")\n",
    "\n",
    "    def convert_to_24h(timestr_12h, ampm):\n",
    "        \"\"\"Convert a 12-hour time with am/pm into 24-hour format.\"\"\"\n",
    "        hour_12, minute = timestr_12h.split(\":\")\n",
    "        hour_12 = int(hour_12)\n",
    "        minute = int(minute)\n",
    "        if hour_12 == 12 and ampm.lower() == \"am\":\n",
    "            return \"00:00\"\n",
    "        if hour_12 == 12 and ampm.lower() == \"pm\":\n",
    "            return f\"12:{minute:02d}\"\n",
    "        if ampm.lower() == \"pm\":\n",
    "            return f\"{hour_12 + 12:02d}:{minute:02d}\"\n",
    "        return f\"{hour_12:02d}:{minute:02d}\"\n",
    "\n",
    "    data_lines = []\n",
    "    for row in lines:\n",
    "        row = row.strip()\n",
    "        # Skip header or blank lines\n",
    "        if not row or row.startswith(\"Date\") or row.startswith(station_title.replace(\"+\", \" \")):\n",
    "            continue\n",
    "\n",
    "        parts = row.split()\n",
    "        # We expect at least 5 tokens (Year, Month, Day, Time, [am/pm?]) plus the numeric columns.\n",
    "        if len(parts) < 5 + expected_numeric_cols:\n",
    "            continue\n",
    "\n",
    "        # Handle potential 12-hour time format\n",
    "        possible_ampm = parts[4].lower()\n",
    "        if possible_ampm in (\"am\", \"pm\"):\n",
    "            time_12h = parts[3]\n",
    "            ampm = parts[4]\n",
    "            offset = 5\n",
    "        else:\n",
    "            time_12h = parts[3]\n",
    "            ampm = None\n",
    "            offset = 4\n",
    "\n",
    "        year_str, month_str, day_str = parts[0], parts[1], parts[2]\n",
    "        time_24 = convert_to_24h(time_12h, ampm) if ampm else time_12h\n",
    "\n",
    "        # Extract numeric columns\n",
    "        numeric_parts = parts[offset:]\n",
    "        if len(numeric_parts) < expected_numeric_cols:\n",
    "            continue\n",
    "        numeric_cols = numeric_parts[:expected_numeric_cols]\n",
    "\n",
    "        # For stations that return 14 numeric columns (e.g., Senator Beck (CSAS)),\n",
    "        # remove the SnoHt column (which is at index 8, zero-indexed).\n",
    "        if expected_numeric_cols == 14:\n",
    "            del numeric_cols[8]\n",
    "\n",
    "        # Build the final output line: Year, Month, Day, HH:MM, then the numeric values.\n",
    "        out_line = f\"{year_str} {month_str} {day_str} {time_24}\"\n",
    "        for val in numeric_cols:\n",
    "            out_line += f\"  {val}\"\n",
    "        data_lines.append(out_line)\n",
    "\n",
    "    return data_lines\n",
    "\n",
    "def build_caic_url(end_date_str=\"2025-03-01+24\", hours_range=72,\n",
    "                   station_title=\"A-Basin+SA-Pali+(A-BasinSA)+11920+ft\",\n",
    "                   station_code=\"CAABP\"):\n",
    "    \"\"\"\n",
    "    Build the URL to fetch data for the given station.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        \"https://stations.avalanche.state.co.us/tabular.php\"\n",
    "        f\"?title={station_title}\"\n",
    "        f\"&st={station_code}\"\n",
    "        f\"&date={end_date_str}\"\n",
    "        \"&unit=e\"\n",
    "        \"&area=caic\"\n",
    "        f\"&range={hours_range}\"\n",
    "    )\n",
    "\n",
    "def build_caic_plot_url(end_date_str=\"2025-03-01+24\", hours_range=72,\n",
    "                        station_title=\"A-Basin+SA-Pali+(A-BasinSA)+11920+ft\",\n",
    "                        station_code=\"CAABP\"):\n",
    "    \"\"\"\n",
    "    Build the URL for plotting data for the given station.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        \"https://stations.avalanche.state.co.us/hplot.php\"\n",
    "        f\"?title={station_title}\"\n",
    "        f\"&st={station_code}\"\n",
    "        f\"&date={end_date_str}\"\n",
    "        \"&unit=e\"\n",
    "        \"&area=caic\"\n",
    "        f\"&range={hours_range}\"\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    end_date_str = \"2025-03-29+24\"  # e.g., midnight leading into Mar 30\n",
    "    hours_range = 24 * 50          # e.g., 50 days of data\n",
    "\n",
    "    # Loop over all station options to scrape and save data for each.\n",
    "    for station_key, station_info in station_options.items():\n",
    "        print(\"Selected station:\", station_key)\n",
    "        caic_url = build_caic_url(\n",
    "            end_date_str,\n",
    "            hours_range,\n",
    "            station_title=station_info[\"station_title\"],\n",
    "            station_code=station_info[\"station_code\"]\n",
    "        )\n",
    "        caic_plot_url = build_caic_plot_url(\n",
    "            end_date_str,\n",
    "            hours_range,\n",
    "            station_title=station_info[\"station_title\"],\n",
    "            station_code=station_info[\"station_code\"]\n",
    "        )\n",
    "    \n",
    "        print(\"URL being fetched:\\n\", caic_url)\n",
    "        print(\"Plot URL being fetched:\\n\", caic_plot_url)\n",
    "    \n",
    "        # Scrape the data using the expected numeric columns for the station.\n",
    "        data_lines = scrape_station_data(\n",
    "            end_date_str,\n",
    "            hours_range,\n",
    "            station_title=station_info[\"station_title\"],\n",
    "            station_code=station_info[\"station_code\"],\n",
    "            expected_numeric_cols=station_info[\"expected_numeric_cols\"]\n",
    "        )\n",
    "    \n",
    "        print(f\"Scraped {len(data_lines)} data rows for station {station_key}.\")\n",
    "    \n",
    "        # Save the output to a text file named after the station (e.g., basin_collect.txt or beck_collect.txt)\n",
    "        out_filename = f\"{station_key.lower()}_collect.txt\"\n",
    "        with open(out_filename, \"w\") as f:\n",
    "            for line in data_lines:\n",
    "                f.write(line + \"\\n\")\n",
    "        print(f\"Wrote {len(data_lines)} lines to {out_filename}.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ATO_4850_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
